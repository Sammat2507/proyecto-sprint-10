{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_data_0 = pd.read_csv('geo_data_0.csv')\n",
    "geo_data_1 = pd.read_csv('geo_data_1.csv')\n",
    "geo_data_2 = pd.read_csv('geo_data_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         f0        f1        f2     product\n",
      "0  0.705745 -0.497823  1.221170  105.280062\n",
      "1  1.334711 -0.340164  4.365080   73.037750\n",
      "2  1.022732  0.151990  1.419926   85.265647\n",
      "3 -0.032172  0.139033  2.978566  168.620776\n",
      "4  1.988431  0.155413  4.751769  154.036647\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count   Dtype  \n",
      "---  ------   --------------   -----  \n",
      " 0   f0       100000 non-null  float64\n",
      " 1   f1       100000 non-null  float64\n",
      " 2   f2       100000 non-null  float64\n",
      " 3   product  100000 non-null  float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 3.1 MB\n"
     ]
    }
   ],
   "source": [
    "geo_data_0 = geo_data_0.drop('id', axis=1)\n",
    "print(geo_data_0.head())\n",
    "geo_data_0.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          f0         f1        f2     product\n",
      "0 -15.001348  -8.276000 -0.005876    3.179103\n",
      "1  14.272088  -3.475083  0.999183   26.953261\n",
      "2   6.263187  -5.948386  5.001160  134.766305\n",
      "3 -13.081196 -11.506057  4.999415  137.945408\n",
      "4  12.702195  -8.147433  5.004363  134.766305\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count   Dtype  \n",
      "---  ------   --------------   -----  \n",
      " 0   f0       100000 non-null  float64\n",
      " 1   f1       100000 non-null  float64\n",
      " 2   f2       100000 non-null  float64\n",
      " 3   product  100000 non-null  float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 3.1 MB\n"
     ]
    }
   ],
   "source": [
    "geo_data_1 = geo_data_1.drop('id', axis=1)\n",
    "print(geo_data_1.head())\n",
    "geo_data_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         f0        f1        f2     product\n",
      "0 -1.146987  0.963328 -0.828965   27.758673\n",
      "1  0.262778  0.269839 -2.530187   56.069697\n",
      "2  0.194587  0.289035 -5.586433   62.871910\n",
      "3  2.236060 -0.553760  0.930038  114.572842\n",
      "4 -0.515993  1.716266  5.899011  149.600746\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count   Dtype  \n",
      "---  ------   --------------   -----  \n",
      " 0   f0       100000 non-null  float64\n",
      " 1   f1       100000 non-null  float64\n",
      " 2   f2       100000 non-null  float64\n",
      " 3   product  100000 non-null  float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 3.1 MB\n"
     ]
    }
   ],
   "source": [
    "geo_data_2 = geo_data_2.drop('id', axis=1)\n",
    "print(geo_data_2.head())\n",
    "geo_data_2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Eliminamos la columna id ya que esta puede interferir en el entrenamiento del modelo debido a que es un string. Ademas esta no aportaba ninguna informacion util al modelo para poder predecir la variable objetivo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Por otro lado no e encontrado ningun valor nulo en el dataset por lo que coinsidero que no deberia haber mas modificaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_0 = geo_data_0['product']\n",
    "features_0 = geo_data_0.drop('product', axis=1)\n",
    "# features_train_0, features_valid_0, target_train_0, target_valid_0 = train_test_split(features_0, target_0, test_size=0.25, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sacamos target y features de la primer region. Ademas los dividimos en train y valid data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_0 = LinearRegression().fit(features_train_0, target_train_0)\n",
    "# valid_predictions_0 = model_0.predict(features_valid_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# product_predictions_mean_0 = valid_predictions_0.mean()\n",
    "# mse_0 = mean_squared_error(valid_predictions_0, target_valid_0)\n",
    "# rmse_0 = np.sqrt(mse_0)\n",
    "# print(rmse_0)\n",
    "# print(product_predictions_mean_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_tester(target, features):\n",
    "    features_train, features_valid, target_train, target_valid = train_test_split(features, target, test_size=0.25, random_state=12345)\n",
    "    model = LinearRegression().fit(features_train, target_train)\n",
    "    valid_predictions = model.predict(features_valid)\n",
    "    product_predictions_mean = valid_predictions.mean()\n",
    "    mse = mean_squared_error(valid_predictions, target_valid)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print(f\"rmse: {rmse}, product mean: {product_predictions_mean}\")\n",
    "    return rmse, product_predictions_mean, valid_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: 37.5794217150813, product mean: 92.59256778438035\n"
     ]
    }
   ],
   "source": [
    "rmse_0, product_predictions_mean_0, valid_predictions_0 = linear_tester(target_0, features_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Para el modelo de la primer region tenemos un rmse un poco alto lo que significa que el modelo puede fallar un poco mas en sus predicciones. Sin embargo tenemos un promedio de posible producto bastante alto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: 0.893099286775617, product mean: 68.72854689544602\n"
     ]
    }
   ],
   "source": [
    "target_1 = geo_data_1['product']\n",
    "features_1 = geo_data_1.drop('product', axis=1)\n",
    "rmse_1, product_predictions_mean_1, valid_predictions_1 = linear_tester(target_1, features_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- En este caso el modelo es muy presiso, esto lo podemos ver gracias a que tiene un rmse muy bajo y lo que nos dicen las predicciones del modelo repsecto a la cantidad de producto promedio es que son un poco mas bajas que en la region uno. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: 40.02970873393434, product mean: 94.96504596800489\n"
     ]
    }
   ],
   "source": [
    "target_2 = geo_data_2['product']\n",
    "features_2 = geo_data_2.drop('product', axis=1)\n",
    "rmse_2, product_predictions_mean_2, valid_predictions_2 = linear_tester(target_2, features_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- En la region numero 3 estamos trabajando con un modelo con casi el mismo rmse que el de la region numero 1 y con un promedio de producto tambien bastante similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- En general considero que la discucion esta entre si apostar a las regiones con mas promedio en producto, teniendo en cuenta que son las que tienen un modelo con mas probabilidad de errar o por otro lado ir por la region 2 que tiene un promedio de producto un poco mas bajo pero su probabilidad de error es muy baja."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-18.507432215619644\n"
     ]
    }
   ],
   "source": [
    "profit_per_well_0 = product_predictions_mean_0 - 111.1\n",
    "print(profit_per_well_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-42.37145310455398\n"
     ]
    }
   ],
   "source": [
    "profit_per_well_1 = product_predictions_mean_1 - 111.1\n",
    "print(profit_per_well_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-16.134954031995107\n"
     ]
    }
   ],
   "source": [
    "profit_per_well_2 = product_predictions_mean_2 - 111.1\n",
    "print(profit_per_well_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Podemos ver que el dado el promedio de producto por pozo en cada region, en principio no se puede cubrir la inversion con ninguna de las regiones. Por esto no vamos a  estar calculando el benefio si no la perdida, esto lo haremos calculando beneficio por pozo multiplicado por el numero de pozos para tener el valor total y a este restarle el valor de la inversion y asi llegar a la perdida. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profit region 1: -100003701.48644312, profit region 2: -100008474.29062091, profit region 3: -100003226.9908064\n"
     ]
    }
   ],
   "source": [
    "invesment = 100000000\n",
    "profit_region_0 = (profit_per_well_0 * 200) - invesment\n",
    "profit_region_1 = (profit_per_well_1 * 200) - invesment\n",
    "profit_region_2 = (profit_per_well_2 * 200) - invesment\n",
    "print(f\"Profit region 1: {profit_region_0}, profit region 2: {profit_region_1}, profit region 3: {profit_region_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- En todas las regiones tenemos perdidas de entre 3000 y 10000 dolares."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ahora vamos a separar los datos predichos en cada region en un ranking de los 200 pozos con un promedio de producto mas alto y vamos a volver calcular el beneficio con estos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_200_wells_0 = pd.Series(valid_predictions_0).nlargest(200)\n",
    "top_200_wells_1 = pd.Series(valid_predictions_1).nlargest(200)\n",
    "top_200_wells_2 = pd.Series(valid_predictions_2).nlargest(200)\n",
    "def best_well_profit(wells_data):\n",
    "    total_product_wells = sum(wells_data)\n",
    "    profit_top_200_wells = (total_product_wells*4500) - invesment\n",
    "    return profit_top_200_wells\n",
    "\n",
    "profit_top_wells_0 = best_well_profit(top_200_wells_0)\n",
    "profit_top_wells_1 = best_well_profit(top_200_wells_1)\n",
    "profit_top_wells_2 = best_well_profit(top_200_wells_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Considero que la mejor region para realizar la inversion es la numero uno, el modelo de esta region no es el que mas precicion tiene, pero tampoco el que menos. Aun asi este es el que mas beneficio predice en el caso de trabajar con los 200 mejores pozos de la region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region 0:\n",
      "  Ganancia media: $39971259.69605701\n",
      "  Intervalo de confianza del 95%: ($39276757.201117545, $40746300.80595794)\n",
      "  Riesgo de pérdidas: 0.0%\n",
      "Region 1:\n",
      "  Ganancia media: $24857431.13553058\n",
      "  Intervalo de confianza del 95%: ($24822601.893553015, $24891918.14388633)\n",
      "  Riesgo de pérdidas: 0.0%\n",
      "Region 2:\n",
      "  Ganancia media: $33225397.55583729\n",
      "  Intervalo de confianza del 95%: ($32534369.443073682, $33869759.04700245)\n",
      "  Riesgo de pérdidas: 0.0%\n"
     ]
    }
   ],
   "source": [
    "def bootstrap(wells, num_samples=1000):\n",
    "    bootstrap_profits = []\n",
    "    for i in range(num_samples):\n",
    "        samples = wells.sample(n=len(wells), replace=True)\n",
    "        profit = best_well_profit(samples)\n",
    "        bootstrap_profits.append(profit)\n",
    "    return bootstrap_profits\n",
    "\n",
    "bootstrap_profits_0 = bootstrap(top_200_wells_0)\n",
    "bootstrap_profits_1 = bootstrap(top_200_wells_1)\n",
    "bootstrap_profits_2 = bootstrap(top_200_wells_2)\n",
    "\n",
    "bootstrap_profits_df = pd.DataFrame({\n",
    "    'Region 0': bootstrap_profits_0,\n",
    "    'Region 1': bootstrap_profits_1,\n",
    "    'Region 2': bootstrap_profits_2\n",
    "})\n",
    "results = {}\n",
    "for region in ['Region 0', 'Region 1', 'Region 2']:\n",
    "    mean_profit = bootstrap_profits_df[region].mean()\n",
    "    confidence_interval = bootstrap_profits_df[region].quantile([0.025, 0.975]).values\n",
    "    risk_of_loss = (bootstrap_profits_df[region] < 0).mean() * 100  \n",
    "    results[region] = {\n",
    "        'mean_profit': mean_profit,\n",
    "        'confidence_interval': confidence_interval,\n",
    "        'risk_of_loss': risk_of_loss\n",
    "    }\n",
    "for region, result in results.items():\n",
    "    print(f\"{region}:\")\n",
    "    print(f\"  Ganancia media: ${result['mean_profit']}\")\n",
    "    print(f\"  Intervalo de confianza del 95%: (${result['confidence_interval'][0]}, ${result['confidence_interval'][1]})\")\n",
    "    print(f\"  Riesgo de pérdidas: {result['risk_of_loss']}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oil_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
