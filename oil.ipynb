{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_data_0 = pd.read_csv('geo_data_0.csv')\n",
    "geo_data_1 = pd.read_csv('geo_data_1.csv')\n",
    "geo_data_2 = pd.read_csv('geo_data_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         f0        f1        f2     product\n",
      "0  0.705745 -0.497823  1.221170  105.280062\n",
      "1  1.334711 -0.340164  4.365080   73.037750\n",
      "2  1.022732  0.151990  1.419926   85.265647\n",
      "3 -0.032172  0.139033  2.978566  168.620776\n",
      "4  1.988431  0.155413  4.751769  154.036647\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count   Dtype  \n",
      "---  ------   --------------   -----  \n",
      " 0   f0       100000 non-null  float64\n",
      " 1   f1       100000 non-null  float64\n",
      " 2   f2       100000 non-null  float64\n",
      " 3   product  100000 non-null  float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 3.1 MB\n"
     ]
    }
   ],
   "source": [
    "geo_data_0 = geo_data_0.drop('id', axis=1)\n",
    "print(geo_data_0.head())\n",
    "geo_data_0.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          f0         f1        f2     product\n",
      "0 -15.001348  -8.276000 -0.005876    3.179103\n",
      "1  14.272088  -3.475083  0.999183   26.953261\n",
      "2   6.263187  -5.948386  5.001160  134.766305\n",
      "3 -13.081196 -11.506057  4.999415  137.945408\n",
      "4  12.702195  -8.147433  5.004363  134.766305\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count   Dtype  \n",
      "---  ------   --------------   -----  \n",
      " 0   f0       100000 non-null  float64\n",
      " 1   f1       100000 non-null  float64\n",
      " 2   f2       100000 non-null  float64\n",
      " 3   product  100000 non-null  float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 3.1 MB\n"
     ]
    }
   ],
   "source": [
    "geo_data_1 = geo_data_1.drop('id', axis=1)\n",
    "print(geo_data_1.head())\n",
    "geo_data_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         f0        f1        f2     product\n",
      "0 -1.146987  0.963328 -0.828965   27.758673\n",
      "1  0.262778  0.269839 -2.530187   56.069697\n",
      "2  0.194587  0.289035 -5.586433   62.871910\n",
      "3  2.236060 -0.553760  0.930038  114.572842\n",
      "4 -0.515993  1.716266  5.899011  149.600746\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count   Dtype  \n",
      "---  ------   --------------   -----  \n",
      " 0   f0       100000 non-null  float64\n",
      " 1   f1       100000 non-null  float64\n",
      " 2   f2       100000 non-null  float64\n",
      " 3   product  100000 non-null  float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 3.1 MB\n"
     ]
    }
   ],
   "source": [
    "geo_data_2 = geo_data_2.drop('id', axis=1)\n",
    "print(geo_data_2.head())\n",
    "geo_data_2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Eliminamos la columna id ya que esta puede interferir en el entrenamiento del modelo debido a que es un string. Ademas esta no aportaba ninguna informacion util al modelo para poder predecir la variable objetivo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Por otro lado no e encontrado ningun valor nulo en el dataset por lo que coinsidero que no deberia haber mas modificaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_0 = geo_data_0['product']\n",
    "features_0 = geo_data_0.drop('product', axis=1)\n",
    "# features_train_0, features_valid_0, target_train_0, target_valid_0 = train_test_split(features_0, target_0, test_size=0.25, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sacamos target y features de la primer region. Ademas los dividimos en train y valid data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_0 = LinearRegression().fit(features_train_0, target_train_0)\n",
    "# valid_predictions_0 = model_0.predict(features_valid_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# product_predictions_mean_0 = valid_predictions_0.mean()\n",
    "# mse_0 = mean_squared_error(valid_predictions_0, target_valid_0)\n",
    "# rmse_0 = np.sqrt(mse_0)\n",
    "# print(rmse_0)\n",
    "# print(product_predictions_mean_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_tester(target, features):\n",
    "    features_train, features_valid, target_train, target_valid = train_test_split(features, target, test_size=0.25, random_state=12345)\n",
    "    model = LinearRegression().fit(features_train, target_train)\n",
    "    valid_predictions = model.predict(features_valid)\n",
    "    product_predictions_mean = valid_predictions.mean()\n",
    "    mse = mean_squared_error(valid_predictions, target_valid)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print(f\"rmse: {rmse}, product mean: {product_predictions_mean}\")\n",
    "    return rmse, product_predictions_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: 37.5794217150813, product mean: 92.59256778438035\n"
     ]
    }
   ],
   "source": [
    "rmse_0, product_predictions_mean_0 = linear_tester(target_0, features_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Para el modelo de la primer region tenemos un rmse un poco alto lo que significa que el modelo puede fallar un poco mas en sus predicciones. Sin embargo tenemos un promedio de posible producto bastante alto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: 0.893099286775617, product mean: 68.72854689544602\n"
     ]
    }
   ],
   "source": [
    "target_1 = geo_data_1['product']\n",
    "features_1 = geo_data_1.drop('product', axis=1)\n",
    "rmse_1, product_predictions_mean_1 = linear_tester(target_1, features_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- En este caso el modelo es muy presiso, esto lo podemos ver gracias a que tiene un rmse muy bajo y lo que nos dicen las predicciones del modelo repsecto a la cantidad de producto promedio es que son un poco mas bajas que en la region uno. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: 40.02970873393434, product mean: 94.96504596800489\n"
     ]
    }
   ],
   "source": [
    "target_2 = geo_data_2['product']\n",
    "features_2 = geo_data_2.drop('product', axis=1)\n",
    "rmse_2, product_predictions_mean_2 = linear_tester(target_2, features_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- En la region numero 3 estamos trabajando con un modelo con casi el mismo rmse que el de la region numero 1 y con un promedio de producto tambien bastante similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- En general considero que la discucion esta entre si apostar a las regiones con mas promedio en producto, teniendo en cuenta que son las que tienen un modelo con mas probabilidad de errar o por otro lado ir por la region 2 que tiene un promedio de producto un poco mas bajo pero su probabilidad de error es muy baja."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oil_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
